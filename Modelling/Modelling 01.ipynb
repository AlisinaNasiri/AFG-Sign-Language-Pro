{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8373afb",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ac5c7c",
   "metadata": {},
   "source": [
    "## Import required moduel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a988160b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-29 14:07:57.298149: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/alisina/anaconda3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/compat/v2_compat.py:96: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0ea4b5",
   "metadata": {},
   "source": [
    "## 1- Prepare the train and test data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb77b920",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load('/home/alisina/Desktop/8th Semester/condidate #2/Code/Sign Language Recognition/Result/Preprocessing/Numpy Array Data & labels/train_data.npy', allow_pickle = True)\n",
    "test_data = np.load(\"/home/alisina/Desktop/8th Semester/condidate #2/Code/Sign Language Recognition/Result/Preprocessing/Numpy Array Data & labels/test_data.npy\", allow_pickle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "859d8224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.ndim # dimensions of train data\n",
    "test_data.ndim # dimensions of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d28c00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Category\n",
    "X_train_data = train_data[::, 0]\n",
    "Y_train_data = train_data[::, 1]\n",
    "\n",
    "# Test Category\n",
    "x_test_data = test_data[::, 0]\n",
    "y_test_data = test_data[::, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd304d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Length of X Train: \", len(X_train_data))\n",
    "print(\"Length of Y Train: \", len(Y_train_data))\n",
    "print()\n",
    "print(\"Length of x Test: \", len(x_test_data))\n",
    "print(\"Length of y Test: \", len(y_test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c789e06",
   "metadata": {},
   "source": [
    "## Scalling the Data\n",
    "* If you don't need to scale data then you can ignore this part and go through to the next part ...\n",
    "* Alert! If you do this part then please ignore the next part and go through to the <b>Create the Model Part</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a9f089",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = X_train_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38965bbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_test_data = x_test_data / 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868d5c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_data = np.array([item for item in X_train_data]).reshape(-1, 96, 96, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf6dce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_data = np.array([item for item in x_train_data]).reshape(-1, 96, 96, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e851e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y train category\n",
    "targets = np.array(Y_train_data).reshape(-1)\n",
    "print(X_train_data[0])\n",
    "print(targets)\n",
    "y_train1 = np.eye(32)[targets]\n",
    "\n",
    "# y test category\n",
    "targets = np.array(y_test_data).reshape(-1)\n",
    "print(x_test_data[0])\n",
    "print(targets)\n",
    "y_test1 = np.eye(32)[targets]\n",
    "\n",
    "# Restore the targets to the previous variables\n",
    "Y_train_data = y_train1\n",
    "y_test_data = y_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04b78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X train length: \", len(X_train_data))\n",
    "print(\"Y train length: \", len(Y_train_data))\n",
    "print(Y_train_data[: 5])\n",
    "print()\n",
    "print(\"x test length: \", len(x_test_data))\n",
    "print(\"y test length: \", len(y_train_data))\n",
    "print(y_test_data[: 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0980dc2",
   "metadata": {},
   "source": [
    "## Categorize and Reshape the Data\n",
    "* Without scalling the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b36c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape of Train Category\n",
    "X_train_data = np.array([item[0] for item in train_data]).reshape(-1, 96, 96, 1)\n",
    "Y_train_data = np.array([item[1] for item in train_data])\n",
    "\n",
    "targets = np.array(Y_train_data).reshape(-1)\n",
    "print(X_train_data[0])\n",
    "print(targets)\n",
    "y_train1 = np.eye(32)[targets]\n",
    "print()\n",
    "print(\"X_train length: \", len(X_train_data), \"Y_train length: \", len(Y_train_data))\n",
    "print()\n",
    "\n",
    "# Reshape of Test Category\n",
    "x_test_data = np.array([item[0] for item in test_data]).reshape(-1, 96, 96, 1)\n",
    "y_test_data = np.array([item[1] for item in test_data])\n",
    "\n",
    "targets = np.array(y_test_data).reshape(-1)\n",
    "print(x_test_data[0])\n",
    "print(targets)\n",
    "y_test1 = np.eye(32)[targets]\n",
    "\n",
    "print()\n",
    "print(\"x_test length: \", len(x_test_data), \"y_test length: \", len(y_test_data))\n",
    "\n",
    "# Restore the targets to the previous variables\n",
    "Y_train_data = y_train1\n",
    "y_test_data = y_test1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c1f8fc",
   "metadata": {},
   "source": [
    "## 2- Create the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e253b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the cnn object.\n",
    "cnn = input_data(shape = [None, 96, 96, 1], name='input')\n",
    "\n",
    "cnn = conv_2d(cnn, 8, 8, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 8)\n",
    "\n",
    "cnn = conv_2d(cnn, 16, 8, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 8)\n",
    "\n",
    "cnn = conv_2d(cnn, 32, 8, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 8)\n",
    "\n",
    "cnn = conv_2d(cnn, 64, 8, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 8)\n",
    "\n",
    "cnn = conv_2d(cnn, 128, 8, activation='relu')\n",
    "cnn = max_pool_2d(cnn, 8)\n",
    "\n",
    "cnn = fully_connected(cnn, 64, activation='relu')\n",
    "cnn = dropout(cnn, 0.30) # Avoid 30% of data overfitting in the model.\n",
    "\n",
    "cnn = fully_connected(cnn, 32, activation='softmax')\n",
    "cnn = regression(cnn, optimizer='adam', learning_rate=0.01, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(cnn, tensorboard_dir='AFG_logs')\n",
    "model.fit(\n",
    "    {'input': X_train_data},\n",
    "    {'targets': Y_train_data},\n",
    "    n_epoch=15,\n",
    "    validation_set=({'input': x_test_data}, {'targets': y_test_data}),\n",
    "    snapshot_step=500,\n",
    "    show_metric=True,\n",
    "    run_id=\"AFG_model_01.model\"\n",
    ")\n",
    "\n",
    "model.save(\"AFG_model_01.model\")\n",
    "score = model.evaluate(x_test_data_data, y_test_data)\n",
    "print('Test accuarcy: %0.4f%%' %(score[0] * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
